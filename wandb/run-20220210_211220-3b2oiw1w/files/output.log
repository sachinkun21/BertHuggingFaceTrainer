--> Reading dataset from dvcfiles/dataset/ner_dataset.csv for training
--> Fitting LabelEncoder on entities and pos
--> Saving the labelEncoder at label_encoder.joblib for inference.
--> Number of NER Classes 17		Number of POS Classes 42
--> Creating Dataloaders with TRAIN_BATCH_SIZE: 64 and VAL_BATCH_SIZE: 32
--> Using cpu for training
--> Initializing the NERModel and setting optimizer
  0%|                                                                                                                             | 0/600 [00:00<?, ?it/s]
  0%|                                                                                                                             | 0/600 [00:12<?, ?it/s]
Traceback (most recent call last):
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\train.py", line 123, in <module>
    train_loss = engine.train_fn(train_dataloader, model, optimizer, device, scheduler, epoch, wandb)
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\engine.py", line 21, in train_fn
    optimizer.step()
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\model.py", line 29, in forward
    output_seq, _ = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\transformers\models\bert\modeling_bert.py", line 996, in forward
    encoder_outputs = self.encoder(
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\transformers\models\bert\modeling_bert.py", line 585, in forward
    layer_outputs = layer_module(
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\transformers\models\bert\modeling_bert.py", line 472, in forward
    self_attention_outputs = self.attention(
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\transformers\models\bert\modeling_bert.py", line 402, in forward
    self_outputs = self.self(
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\torch\nn\modules\module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "C:\Users\kausach\PycharmProjects\NerBERT_HuggingFace\venv\lib\site-packages\transformers\models\bert\modeling_bert.py", line 327, in forward
    attention_scores = attention_scores + attention_mask
KeyboardInterrupt